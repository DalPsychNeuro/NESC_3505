{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "# NESC 3505\n",
        "### Summer 2020\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell imports all the libraries you'll need. Just run it; don't change it at all.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reaction Time Data\n",
        "\n",
        "The cell below contains reaction times from some trials in a behavioural experiment. Execute the cell (shift-enter) and then read the instructions in the cell below it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains the setup you need to complete the assignment. \n",
        "# DO NOT CHANGE ANYTHING IN THIS CELL\n",
        "\n",
        "rt = [0.551714007, 0.344355373, 0.282130643, 0.388339099, 0.741976576, 0.426807824, 0.589848489, 0.341542697, 0.287110004, 0.322289797, 0.379822366, 0.336714422, 0.333802666, 0.293643588, 0.386914908, 0.282874789, 0.383207132, 0.416732649, 0.329448009, 0.554469006, 0.523510978, 0.341133708, 0.508971072, 0.389857974, 0.404175466]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What *type* of data is `rt` (in terms of Python data types)? Use a Python command to generate the answer."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What *type* of data are the individual values in `rt` (in terms of Python data types)? "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the first 10 values in `rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the last 10 values in `rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the values of the tenth through twentieth data points in `rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a Python command to print the number of data points in `rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the slowest reaction time in `rt`? "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the fastest reaction time in `rt`?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which data point (index) in `rt` has the value of 0.341133708?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert `rt` to a NumPy array called `np_rt`, then print `np_rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# do not change the line above; type your answer below\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RT values are in seconds (s). Typically researchers report RTs in milliseconds (ms), which are 1000ths of a second. \n",
        "\n",
        "Convert the RT values to milliseconds, and save them in a new np array called `np_rt_ms`. Print the result. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrate what would happen if you applied the solution above, to `rt` rather than to `np_rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain why you didn't get the desired result when applying the operation to `rt`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a loop to convert the values in `rt` to milliseconds."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# We start by creating an empty variable to append your converted values to. Don't change this line\n",
        "rt_ms = []\n",
        "\n",
        "# Write your loop below:\n",
        "\n",
        "\n",
        "\n",
        "# The line below will allow you to check your results. Don't change it.\n",
        "print(rt_ms)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute and print the mean of the RTs in your numpy array, in milliseconds."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute and print the standard deviation of the RTs in your numpy array, in milliseconds."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D NumPy arrays\n",
        "\n",
        "Now let's create a 2D NumPy array! \n",
        "\n",
        "Below is a new set of data, from the same experiment: error data. The entries here correspond to the trials for which we have RT data, above. Since this is error data, \"False\" means a correct response, and \"True\" means an error. (This is the fun kind of counterintuitive thing you sometimes find in data, especially data created by others. To my mind at least, it would've been more logical to use \"True\" for correct responses...).  \n",
        "\n",
        "Run this cell and move on to the question below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run this cell; don't change anything in it\n",
        "\n",
        "err = [False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, True, True, False, False, False, False, False, False, False]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What Python data type are the values of `err`?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "boolean"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the RTs and error data into a 2D NumPy array called `dat`, and print the result."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the dimensions of `dat`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the data for the fifth and 6th trials in the dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many errors did the participant make?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the error rate — the percentage of trials that were errors. Try to use Python code to get the total number of trials, rather than just copying it from above (that way your code will be more robust; e.g., if you later wanted to use the same code to analyze data with a different number of trials).\n",
        "\n",
        "Save the results in a variable called `err_rate` and print out the percentage."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "What type does Python represent the errors in, in your 2D NumPy array? Do these values look the same as they did in the original `err` variable specified above? Why or why not?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "NumPy converts booleans to floats, because all values in an np array must be of the same type\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## More Data\n",
        "This experiment actually had more than 25 trials! We just gave you some of them to start with. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run this cell; don't change anything in it\n",
        "\n",
        "more_rt = [0.269520309, 0.437764713, 0.368141756, 0.400544278, 0.335198066, 0.341722042, 0.439583357, 0.35481078, 0.341427604, 0.439493392, 0.38420537, 0.352466574, 0.421421653, 0.4923766, 0.332179669, 0.388229602, 0.501321414, 0.546435799, 0.384449907, 0.480385135, 0.389942658, 0.765623791, 0.542873634, 0.560525386, 0.297941768, 0.45605911, 0.325942909, 0.284194214, 0.35981307, 0.342120022, 0.335040395, 0.328463555, 0.775117497, 0.464897611, 0.422927801, 0.356436835, 0.322098869, 0.396105925, 0.38429683, 0.36452361, 0.45407516, 0.494156333, 0.492786617, 0.50683596, 0.340722383, 0.704491148, 0.385229208, 0.470642846, 0.356687005, 0.37682476, 0.372551244, 0.293152987, 0.430451291, 0.709953868, 0.64570153, 0.438242201, 0.492571821, 0.401386526, 0.348756926, 0.53629833, 0.476319524, 0.64048793, 0.575305884, 0.419182746, 0.484022905, 0.417697723, 0.445744469, 0.41918754, 0.552583343, 0.439467594, 0.544988465, 0.63771253, 0.389088011, 0.316212187, 0.403877637, 0.321648505, 0.368134922, 0.385796098, 0.351506951, 0.491596414, 0.405993881, 0.433093893, 0.392526034, 0.396830804, 0.417987737, 0.371810078, 0.659228422, 0.411051235, 0.409580168, 0.486828076, 0.468912134, 0.403514434, 0.495319095, 0.487295343, 0.401069578, 0.515557109, 0.40180221, 0.456425536, 0.388137328, 0.421919935, 0.492101001, 0.479314292, 0.385154687, 0.41581082, 0.38561241, 0.33775059, 0.435691047, 0.338904475, 0.397840528, 0.41243464, 0.388545662, 0.380708986, 0.548247025, 0.35822635, 0.543428436, 0.469808605, 0.313085019, 0.466593928, 0.616256925, 0.466952841, 0.330024424, 0.381547512, 0.342701953, 0.303727031, 0.353838611, 0.40210041, 0.445376428, 0.529948456, 0.31838629, 0.487066979, 0.491859171, 0.313895569, 0.402307654, 0.355419691, 0.303009779, 0.542945377, 0.473349217, 0.332093389, 0.441389659, 0.410761981, 0.382912045, 0.535067053, 0.344429987, 0.44203516, 0.439619433, 0.458289424, 0.407527441, 0.458347813, 0.38038294, 0.483275567, 0.486652597, 0.468253885, 0.864165078, 0.411997088, 0.416620664, 0.461396658, 0.361600953, 0.433055042, 0.508063504, 0.397230403, 0.495033868, 0.382507784, 0.370422818, 0.50719636, 0.39442648, 0.406384457, 0.464322847, 0.410780341, 0.335777049, 0.442713289, 0.384660711, 0.362053288, 0.335582223, 0.405536702, 0.336107944, 0.394837336, 0.343798807, 0.474284578, 0.356018959, 0.327119119, 0.331012891, 0.499155028, 0.3282571, 0.323148876, 0.562998912, 0.429085566, 0.399200255, 0.467921435, 0.412630193, 0.561837517, 0.578094956, 0.407297433, 0.321026407, 0.328112441, 0.482408908, 0.464174871, 0.361424237, 0.411704502, 0.359468468, 0.346170126, 0.607717773, 0.438868968, 0.355754202, 0.391485688, 0.603405711, 0.419079834, 0.443270478, 0.479285645, 0.499684931, 0.485177217, 0.424172705, 0.446263592, 0.539674619, 0.330190823, 0.430980121]\n",
        "more_err = [True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a loop to add (append) these new values to `rt` and `err`. Print out the total number of trials. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a new NumPy array called `full_data`, from the full set of RT and error data. In doing so, convert RTs to milliseconds."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute and print the mean RT across all trials, in milliseconds, rounded to 1 decimal place. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Proivide stem: print(\"Mean RT = \" + YOUR_ANSWER_HERE + \" ms\")\n",
        "print(\"Mean RT = \" +  \" ms\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute and print the median RT across all trials, in milliseconds, rounded to 1 decimal place. The output should start with \"Median RT = \" followed by the computed value."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute and print the standard deviation of the RTs across all trials, in milliseconds, rounded to 2 decimal places. The output should start with \"Standard deviation = \" followed by the computed value."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does this standard deviation compare to the one you computed above for the small set of trials? Why do you think this value changed? (Think back to stats class for this one). "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "As we collect more samples, we get a more accurate estimate of the true mean, and so variance goes down\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a histogram of the RT data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the histogram again, but with twice as many bins. Also, add a title of *Distribution of RTs*, and label the x and y axes as *RT* and *Count*, respectively."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll note that there are a few extreme values — *outliers* — especially at the high end of the range. Sometimes researchers \"trim\" RT data to remove trials on which responses were implausibly fast or slow. Let's say for this experiment that we want to know if any trials had RTs faster than 200 ms or slower than 750 ms. Write Python code that will print out, firstly, any RTs faster than 200 ms, and secondly (separate commands) any RTs slower than 750 ms. Round both answers to 1 decimal place."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a plot to show the number of correct trials, and the number of error trials."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Going Bigger\n",
        "\n",
        "Now we're going to read the full data file from disk.\n",
        "\n",
        "This data file is from an experiment like the one described in the section *Spreadsheets* in Chapter 2 of the textbook.  In this experiment, participants had to press either the left or right arrow key, to indicate whether an arrow shown on the screen is pointing left or right, respectively. However, the catch is that the centre arrow is \"flanked\" by two other arrows on each side; these can be pointing the same way as the target arrow (**congruent**). \n",
        "\n",
        "![flanker_congruent](images/flanker_congruent@0.75x.png)\n",
        "\n",
        "or in the opposite direction (**incongruent**)\n",
        "\n",
        "![flanker_incongruent](images/flanker_incongruent@0.75x.png)\n",
        "\n",
        "The **flanker effect** is an attentional phenomenon in which responses tend to be slower and less accurate when the flankers are incongruent with the centre target than when they are congruent. \n",
        "\n",
        "### Hypotheses\n",
        "For this reason, in this experiment we would generate two **hypotheses**:\n",
        "- **H1:** RTs will be longer (slower) in the incongruent than congruent condition\n",
        "- **H2:** Error rates will be higher in the incongruent than congruent condition"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in Data\n",
        "Read the data file (which is named `s10.csv`) into a pandas DataFrame called `dat`. [Unlike in the lesson video, don't worry about specifying an index for the rows. ]"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the \"head\" of the DataFrame. Be sure the output is a pandas DataFrame and not a Series. You'll know you got it right when it looks like a nicely-formatted table with alternating lines shaded, and column headers (names) right above the corresponding columns."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll see we now have additional information we didn't have earlier: the `trialNum` and `flankers` columns. `trialNum` is, obviously, the number of the trial from start to end of the experiment. `flankers` is the condition of each trial — whether the flankers were congruent or incongruent with the target. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm that this is the same data set as you were working with before, by printing out the mean RT across all trials. (Hint: `mean` is a valid method for pandas DataFrames)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oops, RT is still in seconds! Convert the values in the `rt` column to milliseconds, then print out the head again to confirm it worked."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriptive Statistics\n",
        "Use the `.loc` indexer to compute the mean RT for just the first 25 trials. Compare with the mean RT you computed for the original 25 trials earlier in this assignment, to confirm you're getting the correct result."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now compute the mean RT just for for congruent flankers, and print it out."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the mean RT for incongruent flankers."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the number of errors in each condition, and test whether the error rate is greater for incongruent trials. Here by \"greater\" we simply mean \"numerically larger\", not \"statistically significantly larger\". \n",
        "\n",
        "Print the error rate for each condition (rounded to 3 decimal places, with text that makes it clear which error rate goes with which condition), and result of this test."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Getting loopy!\n",
        "\n",
        "`for` loops are a great way to automate a process, for example when you want to perform the same operation on a bunch of data files. By putting commands inside a `for` loop, you can *iterate* over a bunch of files easily (assuming all the files have the same format).\n",
        "\n",
        "Write a loop that reads in the data files from each of 5 participants. Within the loop, for each participat, print out the participant ID and then mean RTs for each condition, to milliseconds"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this then add your code in the cell below\n",
        "\n",
        "# List of subject IDs, which correspond to file names\n",
        "IDs = ['s10', 's12', 's13', 's14', 's15']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hints\n",
        "\n",
        "- Write the loop from the inside out. That is, start by figuring out how to do this for the first participant's data file. Once you can read in one file and calculate the mean RT, then you can figure out how to loop that across all the participants.\n",
        "- it's helpful to break this down into steps of reading your data into one DataFrame, then computing the meanRTs, then adding them to a new DataFrame. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thought Question\n",
        "\n",
        "This process of automating operations to iterate over a bunch of files helps create fast, autmoated, replicable procedures. For this to work, however, it depends on certain requirements. What do you think would happen if the data files for the questions above were not named systematically as `s10.csv`, `s12.csv`, etc.? For example, what if you, or the person running the study, was not consistent in naming the files, and you had a set of data with the following file names: `s10.csv`, `S12.csv`, `s_13.csv`, `S_14.CSV`, and `subj15.csv`? Why would the loop you wrote above fail? How would you fix this?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}